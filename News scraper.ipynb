{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8f0b849",
   "metadata": {},
   "source": [
    "# News article web scraping "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d4a549",
   "metadata": {},
   "source": [
    "## Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc6b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd40f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ql/xm78crnd19l9q048s8b3qcv00000gn/T/ipykernel_37271/3147183565.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request, sys, time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851fa683",
   "metadata": {},
   "source": [
    "## Times of India "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a0bf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def times_of_india_urls(homepage_url,headless=True):\n",
    "    article_urls = []  # Define an empty list to store article URLs\n",
    "    try:\n",
    "        # Path to the Chrome WebDriver\n",
    "        webdriver_path = '/Users/casarulez/chromedriver-mac-arm64/chromedriver'\n",
    "    \n",
    "\n",
    "       # Configure Chrome options\n",
    "        chrome_options = Options()\n",
    "        if headless:\n",
    "            chrome_options.add_argument('--headless')  # Run in headless mode\n",
    "\n",
    "        # Configure the WebDriver with Chrome options\n",
    "        service = Service(webdriver_path)\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "        try:\n",
    "            # Open the Times of India homepage\n",
    "            driver.get(homepage_url)\n",
    "\n",
    "            # Wait for the article elements to be visible\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.visibility_of_element_located((By.CLASS_NAME, 'col_l_6'))\n",
    "            )\n",
    "\n",
    "            # Extract article URLs\n",
    "            article_divs = driver.find_elements(By.CLASS_NAME, 'col_l_6')  # Replace 'your_div_class' with the actual class name of the div tag\n",
    "            for div in article_divs:\n",
    "                try:\n",
    "                    # Find the <figure> tag within the <div> tag\n",
    "                    figure_tag = div.find_element(By.TAG_NAME, 'figure')\n",
    "                    # Find the <a> tag within the <figure> tag\n",
    "                    a_tag = figure_tag.find_element(By.TAG_NAME, 'a')\n",
    "                    # Get the value of the href attribute from the <a> tag (article URL)\n",
    "                    article_url = a_tag.get_attribute('href')\n",
    "                    # Append the article URL to the list\n",
    "                    article_urls.append(article_url)\n",
    "                except Exception as e:\n",
    "                    continue  # Continue to the next iteration if extraction fails\n",
    "\n",
    "        finally:\n",
    "            # Close the WebDriver\n",
    "            driver.quit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error extracting article URLs:\", e)\n",
    "    \n",
    "    return article_urls  # Return the list of article URLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fb39662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def times_of_india_article(url,headless=True):\n",
    "    try:\n",
    "        # Path to the Chrome WebDriver\n",
    "        webdriver_path = '/Users/casarulez/chromedriver-mac-arm64/chromedriver'\n",
    "        \n",
    "\n",
    "       # Configure Chrome options\n",
    "        chrome_options = Options()\n",
    "        if headless:\n",
    "            chrome_options.add_argument('--headless')  # Run in headless mode\n",
    "\n",
    "        # Configure the WebDriver with Chrome options\n",
    "        service = Service(webdriver_path)\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "        try:\n",
    "            # Open the webpage\n",
    "            driver.get(url)\n",
    "\n",
    "            # Wait for the article elements to be visible\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.visibility_of_element_located((By.CLASS_NAME, 'HNMDR'))\n",
    "            )\n",
    "\n",
    "            # Extract article information\n",
    "            title = driver.find_element(By.CLASS_NAME, 'HNMDR').find_element(By.TAG_NAME, 'span').text.strip()\n",
    "            publication_date = driver.find_element(By.CLASS_NAME, 'xf8Pm.byline').find_element(By.TAG_NAME, 'span').text.strip()\n",
    "            content = driver.find_element(By.CLASS_NAME, '_s30J.clearfix').text.strip()\n",
    "            newspaper_name = 'Times Of India'\n",
    "\n",
    "            article = {\n",
    "                'Title': title,\n",
    "                'Publication Date': publication_date,\n",
    "                'Content': content,\n",
    "                'Newspaper Name': newspaper_name\n",
    "            }\n",
    "\n",
    "            return article\n",
    "        \n",
    "        finally:\n",
    "            # Close the WebDriver\n",
    "            driver.quit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error scraping content:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eda686",
   "metadata": {},
   "source": [
    "## Indian express "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cb56da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indian_express_urls(homepage_url,headless=True):\n",
    "    article_urls = []  # Define an empty list to store article URLs\n",
    "    try:\n",
    "        # Path to the Chrome WebDriver\n",
    "        webdriver_path = '/Users/casarulez/chromedriver-mac-arm64/chromedriver'\n",
    "\n",
    "\n",
    "       # Configure Chrome options\n",
    "        chrome_options = Options()\n",
    "        if headless:\n",
    "            chrome_options.add_argument('--headless')  # Run in headless mode\n",
    "\n",
    "        # Configure the WebDriver with Chrome options\n",
    "        service = Service(webdriver_path)\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "        try:\n",
    "            # Open the Times of India homepage\n",
    "            driver.get(homepage_url)\n",
    "\n",
    "            # Wait for the article elements to be visible\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.visibility_of_element_located((By.CLASS_NAME, 'other-article '))\n",
    "            )\n",
    "\n",
    "            # Extract article URLs\n",
    "            article_divs = driver.find_elements(By.CLASS_NAME, 'other-article ')  # Replace 'your_div_class' with the actual class name of the div tag\n",
    "            for div in article_divs:\n",
    "                try:\n",
    "                    # Find the <figure> tag within the <div> tag\n",
    "                    figure_tag = div.find_element(By.CLASS_NAME, 'content-txt')\n",
    "                    # Find the <a> tag within the <figure> tag\n",
    "                    a_tag = figure_tag.find_element(By.TAG_NAME, 'h3')\n",
    "                    # Get the value of the href attribute from the <a> tag (article URL)\n",
    "                    a_tag2 = a_tag.find_element(By.TAG_NAME, 'a')\n",
    "                    # Get the value of the href attribute from the <a> tag (article URL)\n",
    "                    article_url = a_tag2.get_attribute('href')\n",
    "                    # Append the article URL to the list\n",
    "                    article_urls.append(article_url)\n",
    "                except Exception as e:\n",
    "                    continue  # Continue to the next iteration if extraction fails\n",
    "\n",
    "        finally:\n",
    "            # Close the WebDriver\n",
    "            driver.quit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error extracting article URLs:\", e)\n",
    "    \n",
    "    return article_urls  # Return the list of article URLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fab4142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indian_express_article(url,headless=True):\n",
    "    try:\n",
    "        # Path to the Chrome WebDriver\n",
    "        webdriver_path = '/Users/casarulez/chromedriver-mac-arm64/chromedriver'\n",
    "\n",
    "       # Configure Chrome options\n",
    "        chrome_options = Options()\n",
    "        if headless:\n",
    "            chrome_options.add_argument('--headless')  # Run in headless mode\n",
    "\n",
    "        # Configure the WebDriver with Chrome options\n",
    "        service = Service(webdriver_path)\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "        try:\n",
    "            # Open the webpage\n",
    "            driver.get(url)\n",
    "\n",
    "            # Wait for the article elements to be visible\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.visibility_of_element_located((By.CLASS_NAME, 'row'))\n",
    "            )\n",
    "\n",
    "            # Extract article information\n",
    "            title = driver.find_element(By.CLASS_NAME, 'native_story_title').text.strip()\n",
    "            publication_date = datetime.now().strftime('%B %d, %Y')\n",
    "            content = driver.find_element(By.CLASS_NAME, 'story_details').find_element(By.TAG_NAME, 'p').text.strip()\n",
    "            newspaper_name = 'Indian express'\n",
    "\n",
    "            article = {\n",
    "                'Title': title,\n",
    "                'Publication Date': publication_date,\n",
    "                'Content': content,\n",
    "                'Newspaper Name': newspaper_name\n",
    "            }\n",
    "\n",
    "            return article\n",
    "        \n",
    "        finally:\n",
    "            # Close the WebDriver\n",
    "            driver.quit()\n",
    "\n",
    "    except Exception as e:\n",
    "        #print(\"Error scraping content:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46940f1d",
   "metadata": {},
   "source": [
    "## Deccan chronicle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcccb4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deccan_chronicle_urls(homepage_url, headless=True):\n",
    "    article_urls = []  # Define an empty list to store article URLs\n",
    "    try:\n",
    "        # Path to the Chrome WebDriver\n",
    "        webdriver_path = '/Users/casarulez/chromedriver-mac-arm64/chromedriver'\n",
    "\n",
    "        # Configure Chrome options\n",
    "        chrome_options = Options()\n",
    "        if headless:\n",
    "            chrome_options.add_argument('--headless')  # Run in headless mode\n",
    "\n",
    "        # Configure the WebDriver with Chrome options\n",
    "        service = Service(webdriver_path)\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "        try:\n",
    "            # Open the Deccan Chronicle homepage\n",
    "            driver.get(homepage_url)\n",
    "\n",
    "            # Wait for the article elements to be visible\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.visibility_of_all_elements_located((By.XPATH, '//div[contains(@class, \"col-lg-3\") and contains(@class, \"col-sm-6\") and contains(@class, \"grid-margin\") and contains(@class, \"mb-5\") and contains(@class, \"mb-sm-2\")]'))\n",
    "            )\n",
    "\n",
    "            # Extract article URLs\n",
    "            article_divs = driver.find_elements(By.XPATH, '//div[contains(@class, \"col-lg-3\") and contains(@class, \"col-sm-6\") and contains(@class, \"grid-margin\") and contains(@class, \"mb-5\") and contains(@class, \"mb-sm-2\")]')\n",
    "            for div in article_divs:\n",
    "                try:\n",
    "                    # Find the <h5> tag within the <div> tag\n",
    "                    h5_tag = div.find_element(By.XPATH, './/h5[@class=\"font-weight-bold mt-3 grid-heading\"]')\n",
    "                    # Find the <a> tag within the <h5> tag\n",
    "                    a_tag = h5_tag.find_element(By.TAG_NAME, 'a')\n",
    "                    # Get the value of the href attribute from the <a> tag (article URL)\n",
    "                    article_url = a_tag.get_attribute('href')\n",
    "                    # Append the article URL to the list\n",
    "                    article_urls.append(article_url)\n",
    "                except Exception as e:\n",
    "                    continue  # Continue to the next iteration if extraction fails\n",
    "\n",
    "        finally:\n",
    "            # Close the WebDriver\n",
    "            driver.quit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error extracting article URLs:\", e)\n",
    "    \n",
    "    return article_urls  # Return the list of article URLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff108857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deccan_chronicle_article(url,headless=True):\n",
    "    try:\n",
    "        # Path to the Chrome WebDriver\n",
    "        webdriver_path = '/Users/casarulez/chromedriver-mac-arm64/chromedriver'\n",
    "        \n",
    "\n",
    "       # Configure Chrome options\n",
    "        chrome_options = Options()\n",
    "        if headless:\n",
    "            chrome_options.add_argument('--headless')  # Run in headless mode\n",
    "\n",
    "        # Configure the WebDriver with Chrome options\n",
    "        service = Service(webdriver_path)\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "        try:\n",
    "            # Open the webpage\n",
    "            driver.get(url)\n",
    "\n",
    "            # Wait for the article elements to be visible\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.visibility_of_element_located((By.CLASS_NAME, 'news-post-wrapper-sm'))\n",
    "            )\n",
    "\n",
    "            # Extract article information\n",
    "            title = driver.find_element(By.CSS_SELECTOR, '.news-post-wrapper-sm .text-center.article-title').text.strip()\n",
    "            publication_date = driver.find_element(By.CLASS_NAME, 'date-wrapper').find_element(By.TAG_NAME, 'span').text.strip()\n",
    "            content = driver.find_element(By.CSS_SELECTOR, '.entry-main-content.dropcap > div').text.strip()\n",
    "            newspaper_name = 'The Deccan Chronicle'\n",
    "\n",
    "            article = {\n",
    "                'Title': title,\n",
    "                'Publication Date': publication_date,\n",
    "                'Content': content,\n",
    "                'Newspaper Name': newspaper_name\n",
    "            }\n",
    "\n",
    "            return article\n",
    "        \n",
    "        finally:\n",
    "            # Close the WebDriver\n",
    "            driver.quit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error scraping content:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0eada8",
   "metadata": {},
   "source": [
    "## The mint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a29a2baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_mint_urls(homepage_url,headless=True):\n",
    "    article_urls = []  # Define an empty list to store article URLs\n",
    "    try:\n",
    "        # Path to the Chrome WebDriver\n",
    "        webdriver_path = '/Users/casarulez/chromedriver-mac-arm64/chromedriver'\n",
    "\n",
    "\n",
    "       # Configure Chrome options\n",
    "        chrome_options = Options()\n",
    "        if headless:\n",
    "            chrome_options.add_argument('--headless')  # Run in headless mode\n",
    "\n",
    "        # Configure the WebDriver with Chrome options\n",
    "        service = Service(webdriver_path)\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "        try:\n",
    "            # Open the Times of India homepage\n",
    "            driver.get(homepage_url)\n",
    "\n",
    "            # Wait for the article elements to be visible\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.visibility_of_element_located((By.CLASS_NAME, 'contentBox'))\n",
    "            )\n",
    "\n",
    "            # Extract article URLs\n",
    "            article_divs = driver.find_elements(By.CLASS_NAME, 'contentBox')  # Replace 'your_div_class' with the actual class name of the div tag\n",
    "            for div in article_divs:\n",
    "                try:\n",
    "                    # Find the <figure> tag within the <div> tag\n",
    "                    figure_tag = div.find_element(By.CLASS_NAME, 'newsLinsting')\n",
    "                    # Find the <a> tag within the <figure> tag\n",
    "                    a_tag = figure_tag.find_element(By.CLASS_NAME, 'newsBlock  ')\n",
    "                    # Get the value of the href attribute from the <a> tag (article URL)\n",
    "                    a_tag1 = a_tag.find_element(By.TAG_NAME, 'h3')\n",
    "                    # Get the value of the href attribute from the <a> tag (article URL)\n",
    "                    a_tag2 = a_tag1.find_element(By.TAG_NAME, 'a')\n",
    "                    # Get the value of the href attribute from the <a> tag (article URL)\n",
    "                    article_url = a_tag2.get_attribute('href')\n",
    "                    # Append the article URL to the list\n",
    "                    article_urls.append(article_url)\n",
    "                except Exception as e:\n",
    "                    continue  # Continue to the next iteration if extraction fails\n",
    "\n",
    "        finally:\n",
    "            # Close the WebDriver\n",
    "            driver.quit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error extracting article URLs:\", e)\n",
    "    \n",
    "    return article_urls  # Return the list of article URLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7513dfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_mint_article(url,headless=True):\n",
    "    try:\n",
    "        # Path to the Chrome WebDriver\n",
    "        webdriver_path = '/Users/casarulez/chromedriver-mac-arm64/chromedriver'\n",
    "        \n",
    "\n",
    "       # Configure Chrome options\n",
    "        chrome_options = Options()\n",
    "        if headless:\n",
    "            chrome_options.add_argument('--headless')  # Run in headless mode\n",
    "\n",
    "        # Configure the WebDriver with Chrome options\n",
    "        service = Service(webdriver_path)\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "        try:\n",
    "            # Open the webpage\n",
    "            driver.get(url)\n",
    "\n",
    "            # Wait for the article elements to be visible\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.visibility_of_element_located((By.CLASS_NAME, 'stickyCare'))\n",
    "            )\n",
    "\n",
    "            # Extract article information\n",
    "            title = driver.find_element(By.CSS_SELECTOR, '.headline').text.strip()\n",
    "            publication_date = driver.find_element(By.CLASS_NAME, 'newTimeStamp').text.strip()\n",
    "            content = driver.find_element(By.CLASS_NAME, 'mainArea').find_element(By.TAG_NAME,'p').text.strip()\n",
    "            newspaper_name = 'The mint'\n",
    "\n",
    "            article = {\n",
    "                'Title': title,\n",
    "                'Publication Date': publication_date,\n",
    "                'Content': content,\n",
    "                'Newspaper Name': newspaper_name\n",
    "            }\n",
    "\n",
    "            return article\n",
    "        \n",
    "        finally:\n",
    "            # Close the WebDriver\n",
    "            driver.quit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error scraping content:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888fbf2",
   "metadata": {},
   "source": [
    "## Economic times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85a22075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def economic_times_urls(homepage_url, headless=True):\n",
    "    article_urls = []  # Define an empty list to store article URLs\n",
    "    try:\n",
    "        # Path to the Chrome WebDriver\n",
    "        webdriver_path = '/Users/casarulez/chromedriver-mac-arm64/chromedriver'\n",
    "\n",
    "        # Configure Chrome options\n",
    "        chrome_options = Options()\n",
    "        if headless:\n",
    "            chrome_options.add_argument('--headless')  # Run in headless mode\n",
    "\n",
    "        # Configure the WebDriver with Chrome options\n",
    "        service = Service(webdriver_path)\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "        try:\n",
    "            # Open the Times of India homepage\n",
    "            driver.get(homepage_url)\n",
    "\n",
    "            # Wait for the article elements to be visible\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.visibility_of_element_located((By.XPATH, '//*[@id=\"topStories\"]'))\n",
    "            )\n",
    "\n",
    "            # Find the <ul> tag within the <div> tag\n",
    "            ul_tag = driver.find_element(By.XPATH, '//*[@id=\"topStories\"]/ul')\n",
    "            # Find all <li> tags within the <ul> tag\n",
    "            li_tags = ul_tag.find_elements(By.TAG_NAME, 'li')\n",
    "            # Iterate over each <li> tag\n",
    "            for li_tag in li_tags:\n",
    "                try:\n",
    "                    # Find the <a> tag within the <li> tag\n",
    "                    a_tag = li_tag.find_element(By.TAG_NAME, 'a')\n",
    "                    # Get the value of the href attribute from the <a> tag (article URL)\n",
    "                    article_url = a_tag.get_attribute('href')\n",
    "                    # Append the article URL to the list\n",
    "                    article_urls.append(article_url)\n",
    "                except Exception as e:\n",
    "                    continue  # Continue to the next iteration if extraction fails\n",
    "\n",
    "        finally:\n",
    "            # Close the WebDriver\n",
    "            driver.quit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error extracting article URLs:\", e)\n",
    "\n",
    "    return article_urls  # Return the list of article URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ddbcf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def economic_times_article(url,headless=True):\n",
    "    try:\n",
    "        # Path to the Chrome WebDriver\n",
    "        webdriver_path = '/Users/casarulez/chromedriver-mac-arm64/chromedriver'\n",
    "        \n",
    "\n",
    "       # Configure Chrome options\n",
    "        chrome_options = Options()\n",
    "        if headless:\n",
    "            chrome_options.add_argument('--headless')  # Run in headless mode\n",
    "\n",
    "        # Configure the WebDriver with Chrome options\n",
    "        service = Service(webdriver_path)\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "        try:\n",
    "            # Open the webpage\n",
    "            driver.get(url)\n",
    "\n",
    "            # Wait for the article elements to be visible\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.visibility_of_element_located((By.CLASS_NAME, 'article_wrap'))\n",
    "            )\n",
    "\n",
    "            # Extract article information\n",
    "            title = driver.find_element(By.CSS_SELECTOR, '.artTitle.font_faus').text.strip()\n",
    "            publication_date = driver.find_element(By.CLASS_NAME, 'jsdtTime').text.strip()\n",
    "            content = driver.find_element(By.XPATH, '/html/body/main/div[11]/div/div[1]/div[3]/div/article/div[2]').text.strip()\n",
    "            newspaper_name = 'The economic times'\n",
    "\n",
    "            article = {\n",
    "                'Title': title,\n",
    "                'Publication Date': publication_date,\n",
    "                'Content': content,\n",
    "                'Newspaper Name': newspaper_name\n",
    "            }\n",
    "\n",
    "            return article\n",
    "        \n",
    "        finally:\n",
    "            # Close the WebDriver\n",
    "            driver.quit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error scraping content:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4af9546",
   "metadata": {},
   "source": [
    "## Driver code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f86381a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping content: Message: \n",
      "Stacktrace:\n",
      "0   chromedriver                        0x00000001012d4580 chromedriver + 3966336\n",
      "1   chromedriver                        0x00000001012ccb0c chromedriver + 3934988\n",
      "2   chromedriver                        0x0000000100f4fda0 chromedriver + 277920\n",
      "3   chromedriver                        0x0000000100f92394 chromedriver + 549780\n",
      "4   chromedriver                        0x0000000100fcabf0 chromedriver + 781296\n",
      "5   chromedriver                        0x0000000100f86fb0 chromedriver + 503728\n",
      "6   chromedriver                        0x0000000100f87a28 chromedriver + 506408\n",
      "7   chromedriver                        0x0000000101299768 chromedriver + 3725160\n",
      "8   chromedriver                        0x000000010129dc5c chromedriver + 3742812\n",
      "9   chromedriver                        0x0000000101282250 chromedriver + 3629648\n",
      "10  chromedriver                        0x000000010129e758 chromedriver + 3745624\n",
      "11  chromedriver                        0x00000001012755c8 chromedriver + 3577288\n",
      "12  chromedriver                        0x00000001012bcfb8 chromedriver + 3870648\n",
      "13  chromedriver                        0x00000001012bd15c chromedriver + 3871068\n",
      "14  chromedriver                        0x00000001012cc77c chromedriver + 3934076\n",
      "15  libsystem_pthread.dylib             0x0000000180af6034 _pthread_start + 136\n",
      "16  libsystem_pthread.dylib             0x0000000180af0e3c thread_start + 8\n",
      "\n",
      "Error scraping content: Message: \n",
      "Stacktrace:\n",
      "0   chromedriver                        0x00000001049a8580 chromedriver + 3966336\n",
      "1   chromedriver                        0x00000001049a0b0c chromedriver + 3934988\n",
      "2   chromedriver                        0x0000000104623da0 chromedriver + 277920\n",
      "3   chromedriver                        0x0000000104666394 chromedriver + 549780\n",
      "4   chromedriver                        0x000000010469ebf0 chromedriver + 781296\n",
      "5   chromedriver                        0x000000010465afb0 chromedriver + 503728\n",
      "6   chromedriver                        0x000000010465ba28 chromedriver + 506408\n",
      "7   chromedriver                        0x000000010496d768 chromedriver + 3725160\n",
      "8   chromedriver                        0x0000000104971c5c chromedriver + 3742812\n",
      "9   chromedriver                        0x0000000104956250 chromedriver + 3629648\n",
      "10  chromedriver                        0x0000000104972758 chromedriver + 3745624\n",
      "11  chromedriver                        0x00000001049495c8 chromedriver + 3577288\n",
      "12  chromedriver                        0x0000000104990fb8 chromedriver + 3870648\n",
      "13  chromedriver                        0x000000010499115c chromedriver + 3871068\n",
      "14  chromedriver                        0x00000001049a077c chromedriver + 3934076\n",
      "15  libsystem_pthread.dylib             0x0000000180af6034 _pthread_start + 136\n",
      "16  libsystem_pthread.dylib             0x0000000180af0e3c thread_start + 8\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m extracted_articles \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m times_of_india_extracted_urls:\n\u001b[0;32m---> 18\u001b[0m     article_data \u001b[38;5;241m=\u001b[39m \u001b[43mtimes_of_india_article\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheadless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m article_data:\n\u001b[1;32m     20\u001b[0m         extracted_articles\u001b[38;5;241m.\u001b[39mappend(article_data)\n",
      "Cell \u001b[0;32mIn [3], line 18\u001b[0m, in \u001b[0;36mtimes_of_india_article\u001b[0;34m(url, headless)\u001b[0m\n\u001b[1;32m     14\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome(service\u001b[38;5;241m=\u001b[39mservice, options\u001b[38;5;241m=\u001b[39mchrome_options)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Open the webpage\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Wait for the article elements to be visible\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     WebDriverWait(driver, \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(\n\u001b[1;32m     22\u001b[0m         EC\u001b[38;5;241m.\u001b[39mvisibility_of_element_located((By\u001b[38;5;241m.\u001b[39mCLASS_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHNMDR\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     23\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:356\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:345\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m    343\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[0;32m--> 345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py:302\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    300\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[1;32m    301\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py:322\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    319\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 322\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/urllib3/_request_methods.py:144\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[1;32m    137\u001b[0m         method,\n\u001b[1;32m    138\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/urllib3/_request_methods.py:279\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    275\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[1;32m    277\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/urllib3/poolmanager.py:444\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    442\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/urllib3/connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/urllib3/connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/urllib3/connection.py:466\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    465\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the filename for the CSV file\n",
    "csv_filename = 'extracted_articles.csv'\n",
    "\n",
    "times_of_india_extracted_urls = times_of_india_urls('https://timesofindia.indiatimes.com/', headless=True)\n",
    "deccan_chronicle_extracted_urls=deccan_chronicle_urls('https://www.deccanchronicle.com/', headless=True)\n",
    "indian_express_extracted_urls = indian_express_urls('https://indianexpress.com/', headless=True)\n",
    "the_mint_extracted_urls = the_mint_urls('https://www.livemint.com/', headless=True)\n",
    "economic_times_extracted_urls = economic_times_urls('https://economictimes.indiatimes.com/', headless=True)\n",
    "\n",
    "\n",
    "extracted_articles = []\n",
    "\n",
    "\n",
    "for url in times_of_india_extracted_urls:\n",
    "    article_data = times_of_india_article(url, headless=True)\n",
    "    if article_data:\n",
    "        extracted_articles.append(article_data)\n",
    "\n",
    "for url in indian_express_extracted_urls:\n",
    "    article_data = indian_express_article(url, headless=True)\n",
    "    if article_data:\n",
    "        extracted_articles.append(article_data)\n",
    "\n",
    "\n",
    "for url in deccan_chronicle_extracted_urls:\n",
    "    article_data = deccan_chronicle_article(url, headless=True)\n",
    "    if article_data:\n",
    "        extracted_articles.append(article_data)\n",
    "        \n",
    "for url in the_mint_extracted_urls:\n",
    "    article_data = the_mint_article(url, headless=True)\n",
    "    if article_data:\n",
    "        extracted_articles.append(article_data)\n",
    "        \n",
    "for url in economic_times_extracted_urls:\n",
    "    article_data = economic_times_article(url, headless=True)\n",
    "    if article_data:\n",
    "        extracted_articles.append(article_data)\n",
    "        \n",
    "        \n",
    "if extracted_articles:\n",
    "    df = pd.DataFrame(extracted_articles)\n",
    "\n",
    "    # Check if the CSV file exists\n",
    "    if os.path.exists(csv_filename):\n",
    "        # Append to existing CSV file\n",
    "        df.to_csv(csv_filename, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        # Create new CSV file\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "    print(\"Data appended to CSV file:\", csv_filename)\n",
    "else:\n",
    "    print(\"Error: Unable to scrape any articles.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e179dc",
   "metadata": {},
   "source": [
    "## Testing URL extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4970863",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://economictimes.indiatimes.com/markets/stocks/news/pizza-burger-or-chicken-rs-80000-crore-question-haunting-investors-in-qsr-stocks/articleshow/108030403.cms', 'https://economictimes.indiatimes.com/nri/migrate/why-the-us-economy-needs-more-immigrants/articleshow/108034275.cms', 'https://economictimes.indiatimes.com/news/economy/finance/states-borrowing-cost-decline-marginally-to-7-44-per-cent/articleshow/108048624.cms', 'https://economictimes.indiatimes.com/markets/stocks/news/vodafone-idea-plans-to-raise-rs-45000-crore-via-equity-debt/articleshow/108047916.cms', 'https://economictimes.indiatimes.com/news/international/business/mizuho-courting-india-elite-shows-japan-banks-global-ambition/articleshow/108034546.cms', 'https://economictimes.indiatimes.com/markets', 'https://economictimes.indiatimes.com/markets/stocks/news/ahead-of-market-10-things-that-will-decide-d-street-action-on-wednesday/articleshow/108050545.cms', 'https://economictimes.indiatimes.com/markets/stocks/news/market-trading-guide-tata-motors-pb-fintech-among-3-stock-recommendations-for-wednesday/stock-ideas/slideshow/108049000.cms', 'https://economictimes.indiatimes.com/mf/analysis/mfs-favourite-these-7-microcap-stocks-rallied-100-600-in-fy24-so-far/articleshow/108046145.cms', 'https://economictimes.indiatimes.com/etmarkets-livestream?utm_source=MainHome&utm_medium=Self-Referrals', 'https://economictimes.indiatimes.com/markets/etmarkets-live/streamsrecorded/streamid-npnf5trg6u,expertid-25.cms?utm_source=MainHome&utm_medium=Self-Referrals', 'https://economictimes.indiatimes.com/markets/etmarkets-live/streamsrecorded/streamid-npnf5tng6u,expertid-29.cms?utm_source=MainHome&utm_medium=Self-Referrals', 'https://economictimes.indiatimes.com/markets/etmarkets-live/streamsrecorded/streamid-npnf5a4g6u,expertid-89.cms?utm_source=MainHome&utm_medium=Self-Referrals', 'https://economictimes.indiatimes.com/markets/etmarkets-live/streamsrecorded/streamid-npnf5a8g6u,expertid-91.cms?utm_source=MainHome&utm_medium=Self-Referrals', 'https://economictimes.indiatimes.com/news/newsblogs/daily-news-and-latest-updates-parliament-lok-sabha-elections-rjaya-sabha-polls-farmers-protest-sandeshkhali-pm-modi-tmc-mamata-congress-rahul-gandhi-bjp-aap-kejriwal-live-27-february-2024/liveblog/108025850.cms', 'https://economictimes.indiatimes.com/news/international/world-news/new-zealand-set-to-scrap-world-first-tobacco-ban/articleshow/108051555.cms', 'https://economictimes.indiatimes.com/news/politics-and-nation/ncp-leader-praful-patel-resigns-from-rajya-sabha-ahead-of-fresh-full-term/articleshow/108050678.cms', 'https://economictimes.indiatimes.com/news/politics-and-nation/bjp-wins-eight-rajya-sabha-seats-sp-bags-two-seats-in-up/articleshow/108050334.cms', 'https://economictimes.indiatimes.com/news/india/court-asks-police-to-arrest-jaya-prada-and-produce-her-before-it-on-march-6/articleshow/108049771.cms', 'https://economictimes.indiatimes.com/industry/healthcare/biotech/pharmaceuticals/will-indias-pharma-sector-be-able-to-come-out-of-its-china-dependence/articleshow/108048363.cms', 'https://economictimes.indiatimes.com/news/politics-and-nation/bjp-candidate-harsh-mahajan-wins-lone-rajya-sabha-seat-from-himachal-pradesh/articleshow/108049117.cms', 'https://economictimes.indiatimes.com/news/politics-and-nation/rajya-sabha-elections-crpf-haryana-police-convoy-have-taken-away-5-6-congress-mlas-himachal-cm-sukhvinder-sukhu/articleshow/108048720.cms', 'https://economictimes.indiatimes.com/news/politics-and-nation/rajya-sabha-polls-congress-wins-three-seats-bjp-bags-one-in-karnataka/articleshow/108047638.cms', 'https://economictimes.indiatimes.com/news/politics-and-nation/ministry-of-home-affairs-to-potentially-notify-caa-rules-before-model-code-of-conduct/articleshow/108047341.cms', 'https://economictimes.indiatimes.com/markets/expert-view/platinum-industries-cmd-on-ipo-sustaining-financials-and-ambitious-expansion-plans/articleshow/108044275.cms', 'https://economictimes.indiatimes.com/industry/banking/finance/gift-city-taps-rbi-for-rtgs-like-dollar-payment-system/articleshow/108022156.cms', 'https://economictimes.indiatimes.com/news/elections/lok-sabha/india/lok-sabha-polls-aap-announces-4-candidates-from-delhi-1-from-haryana/articleshow/108043935.cms', 'https://economictimes.indiatimes.com/markets/expert-view/8-10-correction-likely-in-nifty-as-well-as-broader-markets-amit-khurana/articleshow/108043406.cms', 'https://economictimes.indiatimes.com/wealth/personal-finance-news/family-of-deceased-housewife-wins-rs-6-lakh-in-sc-homemaking-not-a-valid-ground-for-low-payout-to-accident-victim/articleshow/108016614.cms', 'https://economictimes.indiatimes.com/markets/stocks/news/sebi-asks-small-mid-cap-funds-to-disclose-more-about-risks/articleshow/108038796.cms', 'https://economictimes.indiatimes.com/industry/transportation/railways/railway-reduces-ticket-prices-for-passenger-trains-by-50-here-are-details/articleshow/108043247.cms', 'https://economictimes.indiatimes.com/industry/services/hotels-/-restaurants/check-into-5-star-luxury-and-you-need-not-check-out/articleshow/108022275.cms', 'https://economictimes.indiatimes.com/wealth/tax/nps-investment-can-save-you-tax-on-income-upto-rs-9-5-lakh-under-old-new-tax-regime-heres-how/articleshow/108031158.cms', 'https://economictimes.indiatimes.com/wealth/save/feb-29-last-date-to-update-fastag-kyc-step-by-step-guide-on-how-to-update-fastag-kyc/articleshow/108040146.cms', 'https://economictimes.indiatimes.com/wealth/invest/sovereign-gold-bond-sgb-premature-redemption-dates-for-april-2024-september-2024-announced-check-details/articleshow/108041676.cms', 'https://economictimes.indiatimes.com/markets/expert-view/no-red-flag-in-market-but-expect-low-teens-returns-siddharth-srivastava/articleshow/108041611.cms', 'https://economictimes.indiatimes.com/news/defence/indigenously-designed-and-manufactured-modular-bridge-inducted-into-indian-army/articleshow/108042214.cms', 'https://economictimes.indiatimes.com/news/india/misleading-ads-case-sc-issues-patanjalis-ramdev-notice-says-govt-is-sitting-with-its-eyes-closed/articleshow/108040746.cms', 'https://economictimes.indiatimes.com/wealth/tax/how-section-80c-of-the-income-tax-act-can-help-you-save-tax/articleshow/108035333.cms', 'https://economictimes.indiatimes.com/wealth/save/aadhaar-card-update-how-to-change-your-aadhaar-photo-online-offline/articleshow/108033010.cms', 'https://economictimes.indiatimes.com/markets/expert-view/bank-nifty-is-way-weaker-than-nifty-positive-on-realty-pharma-sectors-meghana-malkan/articleshow/108038057.cms', 'https://economictimes.indiatimes.com/industry/banking/finance/banking/icici-bank-customer-accuses-manager-of-stealing-rs-16-crore-from-her-fds-bank-responds/articleshow/108034676.cms', 'https://economictimes.indiatimes.com/news/company/corporate-trends/nclt-approves-hinduja-groups-revival-plan-for-anil-ambani-promoted-reliance-capital/articleshow/108031649.cms']\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "url_test=economic_times_urls('https://economictimes.indiatimes.com/', headless=False)\n",
    "print(url_test)\n",
    "print(len(url_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d496c",
   "metadata": {},
   "source": [
    "## Testing article extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c92982c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_articles_test=[]\n",
    "for url in range(0,3):\n",
    "    article_data = deccan_times_article(url_test[url], headless=False)\n",
    "    if article_data:\n",
    "        extracted_articles_test.append(article_data)\n",
    "        df_test = pd.DataFrame(extracted_articles_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4cd6f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Publication Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>Newspaper Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pizza, burger or chicken? Rs 80,000 crore ques...</td>\n",
       "      <td>Last Updated: Feb 27, 2024, 11:11:00 PM IST</td>\n",
       "      <td>As competition among quick service restaurants...</td>\n",
       "      <td>The economic times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why the US economy needs more immigrants</td>\n",
       "      <td>Last Updated: Feb 27, 2024, 04:19:00 PM IST</td>\n",
       "      <td>A recent surge in immigration to the United St...</td>\n",
       "      <td>The economic times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>States' borrowing cost decline marginally to 7...</td>\n",
       "      <td>Last Updated: Feb 27, 2024, 07:38:00 PM IST</td>\n",
       "      <td>The borrowing cost for states continued to fal...</td>\n",
       "      <td>The economic times</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Pizza, burger or chicken? Rs 80,000 crore ques...   \n",
       "1           Why the US economy needs more immigrants   \n",
       "2  States' borrowing cost decline marginally to 7...   \n",
       "\n",
       "                              Publication Date  \\\n",
       "0  Last Updated: Feb 27, 2024, 11:11:00 PM IST   \n",
       "1  Last Updated: Feb 27, 2024, 04:19:00 PM IST   \n",
       "2  Last Updated: Feb 27, 2024, 07:38:00 PM IST   \n",
       "\n",
       "                                             Content      Newspaper Name  \n",
       "0  As competition among quick service restaurants...  The economic times  \n",
       "1  A recent surge in immigration to the United St...  The economic times  \n",
       "2  The borrowing cost for states continued to fal...  The economic times  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02233aa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extracted_articles_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6773bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
